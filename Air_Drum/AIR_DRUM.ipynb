{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/66/82/564168a349148298aca281e342551404ef5521f33fba17b388ead0a84dc5/opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/tarunshyam/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.24.3)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.org/project/opencv-python/\n",
    "pip install opencv-python\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Obtaining dependency information for pygame from https://files.pythonhosted.org/packages/6b/37/6c03fadba5af47d7144bbe517488b0f5b0072ad01f093318db1e37a9f34f/pygame-2.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pygame-2.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Downloading pygame-2.6.0-cp311-cp311-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m96.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:04\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Successfully installed pygame-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#https://www.pygame.org/wiki/GettingStarted\n",
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import time \n",
    "import cv2\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbsoe = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "drum_clap = mixer.Sound('batterrm.wav')\n",
    "drum_snare = mixer.Sound('button-2.ogg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV color model\n",
    "\n",
    "HSV stands for Hue, Saturation, Value:\n",
    "\n",
    "Hue (H): Represents the color type (0 to 360 degrees on the color wheel).\n",
    "Saturation (S): Indicates the intensity of the color (0 to 100%). Higher values mean more vivid colors.\n",
    "Value (V): Reflects the brightness of the color (0 to 100%). Higher values indicate lighter colors.\n",
    "This model is useful in computer graphics and image processing for manipulating and selecting colors intuitively.\n",
    "\n",
    "Hue/color type :\n",
    "\n",
    "0° - 30°: Red\n",
    "\n",
    "30° - 60°: Orange\n",
    "\n",
    "60° - 90°: Yellow\n",
    "\n",
    "90° - 150°: Green\n",
    "\n",
    "150° - 210°: Cyan\n",
    "\n",
    "210° - 270°: Blue\n",
    "\n",
    "270° - 330°: Purple\n",
    "\n",
    "330° - 360°: Magenta/Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV range for detecting blue colour \n",
    "orangeLower = (10,150,50)\n",
    "orangeUpper = (25,255,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above lines we set the values to detect the blue colour. These values will be used in the [creating mask](# creating mask ) to find pixels corresponding to blue colour inside the ROI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing frames from camera and determining the frame size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame accusation from webcam/ usb camera \n",
    "camera = cv2.VideoCapture(0)\n",
    "ret,frame = camera.read()\n",
    "\n",
    "# Determining the frame resolution (height,width)\n",
    "H,W = frame.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the image of instrument to be augmented with fixed size (200,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1104.437] global loadsave.cpp:241 findDecoder imread_('hat.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# reading the image of hatt and snare for augumentation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Hatt \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhat.png\u001b[39m\u001b[38;5;124m'\u001b[39m),(\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m100\u001b[39m),interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_CUBIC)\n\u001b[1;32m      3\u001b[0m Snare \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize (cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnare.png\u001b[39m\u001b[38;5;124m'\u001b[39m),(\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m100\u001b[39m),interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_CUBIC)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "# reading the image of hatt and snare for augumentation\n",
    "Hatt = cv2.resize(cv2.imread('hat.png'),(200,100),interpolation=cv2.INTER_CUBIC)\n",
    "Snare = cv2.resize (cv2.imread('snare.png'),(200,100),interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the image of hatt and snare for augmentation.\n",
    "Hatt = cv2.resize(cv2.imread('HATT.png'),(200,100),interpolation=cv2.INTER_CUBIC)\n",
    "Snare = cv2.resize(cv2.imread('SNARE.png'),(200,100),interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Region of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region of interest is the black colour portion in the image below,\n",
    "\n",
    "Why ROI is needed?\n",
    "\n",
    "Answer is Speed. To detect blue colour we need to perform certain operations on each captured frame. These operations need some computations to be performed by the processor. Since our instruments are fixed in this application and we want to play the sound only if the blue colour object hits the instrument (detected inside the ROI) it is a good idea to perform all these operations only inside the ROI.\n",
    "\n",
    "With the below lines of code we calculate the top left and bottom right corners of the ROI corresponding to both the instruments Hatt and Snare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the corners of ROI for blue colour detection\n",
    "Hatt_center = [np.shape(frame)[1]*2//8,np.shape(frame)[0]*6//8]\n",
    "Snare_center = [np.shape(frame)[1]*6//8,np.shape(frame)[0]*6//8]\n",
    "Hatt_thickness = [200,100]\n",
    "Hatt_top = [Hatt_center[0]-Hatt_thickness[0]//2,Hatt_center[1]-Hatt_thickness[1]//2]\n",
    "Hatt_btm = [Hatt_center[0]+Hatt_thickness[0]//2,Hatt_center[1]+Hatt_thickness[1]//2]\n",
    "\n",
    "Snare_thickness = [200,100]\n",
    "Snare_top = [Snare_center[0]-Snare_thickness[0]//2,Snare_center[1]-Snare_thickness[1]//2]\n",
    "Snare_btm = [Snare_center[0]+Snare_thickness[0]//2,Snare_center[1]+Snare_thickness[1]//2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the while loop....\n",
    "\n",
    "capture camera frame and store it in a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = camera.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.flip(frame,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the ROI corresponding to Snare and Hatt. ROI is selected by indexing the rows and columns of the image frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img[a:b,c:d]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img[a:b,c:d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ROI_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Selecting ROI corresponding to snare\u001b[39;00m\n\u001b[1;32m      2\u001b[0m snare_ROI \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(frame[Snare_top[\u001b[38;5;241m1\u001b[39m]:Snare_btm[\u001b[38;5;241m1\u001b[39m],Snare_top[\u001b[38;5;241m0\u001b[39m]:Snare_btm[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m----> 3\u001b[0m mask \u001b[38;5;241m=\u001b[39m ROI_analysis(snare_ROI,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Selecting ROI corresponding to Hatt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m hatt_ROI \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(frame[Hatt_top[\u001b[38;5;241m1\u001b[39m]:Hatt_btm[\u001b[38;5;241m1\u001b[39m],Hatt_top[\u001b[38;5;241m0\u001b[39m]:Hatt_btm[\u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ROI_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "# Selecting ROI corresponding to snare\n",
    "snare_ROI = np.copy(frame[Snare_top[1]:Snare_btm[1],Snare_top[0]:Snare_btm[0]])\n",
    "mask = ROI_analysis(snare_ROI,1)\n",
    "\n",
    "# Selecting ROI corresponding to Hatt\n",
    "hatt_ROI = np.copy(frame[Hatt_top[1]:Hatt_btm[1],Hatt_top[0]:Hatt_btm[0]])\n",
    "mask = ROI_analysis(hatt_ROI,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Verbsoe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject: Air Drums\u001b[39m\u001b[38;5;124m'\u001b[39m,(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m),\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m),\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Display the ROI to view the blue colour being detected\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Verbsoe:\n\u001b[1;32m      9\u001b[0m     frame[Snare_top[\u001b[38;5;241m1\u001b[39m]:Snare_btm[\u001b[38;5;241m1\u001b[39m],Snare_top[\u001b[38;5;241m0\u001b[39m]:Snare_btm[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m    cv2\u001b[38;5;241m.\u001b[39mbitwise_and(frame[Snare_top[\u001b[38;5;241m1\u001b[39m]:Snare_btm[\u001b[38;5;241m1\u001b[39m],Snare_top[\u001b[38;5;241m0\u001b[39m]:Snare_btm[\u001b[38;5;241m0\u001b[39m]],frame[Snare_top[\u001b[38;5;241m1\u001b[39m]:Snare_btm[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     10\u001b[0m     Snare_top[\u001b[38;5;241m0\u001b[39m]:Snare_btm[\u001b[38;5;241m0\u001b[39m]], mask\u001b[38;5;241m=\u001b[39mmask[Snare_top[\u001b[38;5;241m1\u001b[39m]:Snare_btm[\u001b[38;5;241m1\u001b[39m],Snare_top[\u001b[38;5;241m0\u001b[39m]:Snare_btm[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m     11\u001b[0m     frame[Hatt_top[\u001b[38;5;241m1\u001b[39m]:Hatt_btm[\u001b[38;5;241m1\u001b[39m],Hatt_top[\u001b[38;5;241m0\u001b[39m]:Hatt_btm[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_and(frame[Hatt_top[\u001b[38;5;241m1\u001b[39m]:Hatt_btm[\u001b[38;5;241m1\u001b[39m],Hatt_top[\u001b[38;5;241m0\u001b[39m]:Hatt_btm[\u001b[38;5;241m0\u001b[39m]],frame[Hatt_top[\u001b[38;5;241m1\u001b[39m]:Hatt_btm[\u001b[38;5;241m1\u001b[39m],Hatt_top[\u001b[38;5;241m0\u001b[39m]:Hatt_btm[\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m     12\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask[Hatt_top[\u001b[38;5;241m1\u001b[39m]:Hatt_btm[\u001b[38;5;241m1\u001b[39m],Hatt_top[\u001b[38;5;241m0\u001b[39m]:Hatt_btm[\u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Verbsoe' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# A writing text on an image.\n",
    "cv2.putText(frame,'Project: Air Drums',(10,30),2,1,(20,20,20),2)\n",
    "\n",
    "# A writing text on an image.\n",
    "cv2.putText(frame,'Project: Air Drums',(10,30),2,1,(20,20,20),2)\n",
    "\n",
    "# Display the ROI to view the blue colour being detected\n",
    "if Verbsoe:\n",
    "    frame[Snare_top[1]:Snare_btm[1],Snare_top[0]:Snare_btm[0]] =    cv2.bitwise_and(frame[Snare_top[1]:Snare_btm[1],Snare_top[0]:Snare_btm[0]],frame[Snare_top[1]:Snare_btm[1],\n",
    "    Snare_top[0]:Snare_btm[0]], mask=mask[Snare_top[1]:Snare_btm[1],Snare_top[0]:Snare_btm[0]])\n",
    "    frame[Hatt_top[1]:Hatt_btm[1],Hatt_top[0]:Hatt_btm[0]] = cv2.bitwise_and(frame[Hatt_top[1]:Hatt_btm[1],Hatt_top[0]:Hatt_btm[0]],frame[Hatt_top[1]:Hatt_btm[1],Hatt_top[0]:Hatt_btm[0]],\n",
    "    mask=mask[Hatt_top[1]:Hatt_btm[1],Hatt_top[0]:Hatt_btm[0]])\n",
    "    \n",
    "    # Augmenting the instruments in the output frame.\n",
    "else:\n",
    "    # Augmenting the image of the instruments on the frame.\n",
    "    frame[Snare_top[1]:Snare_btm[1],Snare_top[0]:Snare_btm[0]] = cv2.addWeighted(Snare, 1, frame[Snare_top[1]:Snare_btm[1],Snare_top[0]:Snare_btm[0]], 1, 0)\n",
    "    frame[Hatt_top[1]:Hatt_btm[1],Hatt_top[0]:Hatt_btm[0]] = cv2.addWeighted(Hatt, 1, frame[Hatt_top[1]:Hatt_btm[1],Hatt_top[0]:Hatt_btm[0]], 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
